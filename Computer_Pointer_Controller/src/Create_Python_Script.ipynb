{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "#import os\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from input_feeder import InputFeeder\n",
    "#from mouse_controller import MouseController\n",
    "\n",
    "from face_detection import ModelFaceDetection\n",
    "from head_pose_estimation import ModelHeadPoseEstimation\n",
    "from facial_landmarks_detection import ModelFacialLandmarksDetection\n",
    "from gaze_estimation import ModelGazeEstimation\n",
    "\n",
    "def main(args):\n",
    "    start_model_load_time=time.time()\n",
    "\n",
    "    # load model\n",
    "    class_face_detection = ModelFaceDetection(args.model_face_detection, args.device, args.threshold)\n",
    "    class_face_detection.load_model()\n",
    "\n",
    "    class_head_pose_estimation = ModelHeadPoseEstimation(args.model_head_pose_estimation, args.device)\n",
    "    class_head_pose_estimation.load_model()\n",
    "\n",
    "    class_facial_landmarks_detection = ModelFacialLandmarksDetection(args.model_facial_landmarks_detection, args.device)\n",
    "    class_facial_landmarks_detection.load_model()\n",
    "\n",
    "    class_gaze_estimation = ModelGazeEstimation(args.model_gaze_estimation, args.device)\n",
    "    class_gaze_estimation.load_model()\n",
    "\n",
    "    total_model_load_time = time.time() - start_model_load_time\n",
    "\n",
    "    # input image\n",
    "    feed=InputFeeder(input_type='video', input_file=args.input_path)\n",
    "    feed.load_data()\n",
    "\n",
    "    # output\n",
    "    initial_w, initial_h, initial_fps = feed.get_info()\n",
    "\n",
    "    counter = 0\n",
    "    start_inference_time = time.time()\n",
    "\n",
    "    # debug\n",
    "    #print(\"initial_w:{}, initial_h:{}, initial_fps:{}\".format(initial_w, initial_h, initial_fps))\n",
    "\n",
    "    #out_video = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), initial_fps, (initial_w, initial_h), True)\n",
    "    out_video = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (initial_w, initial_h), True)\n",
    "\n",
    "    class_face_detection.initial_size(initial_w, initial_h)\n",
    "\n",
    "    #mc = MouseController(precision='low', speed='slow')\n",
    "    #mc = MouseController(precision='high', speed='fast')\n",
    "\n",
    "    for flag, batch in feed.next_batch():\n",
    "        if not flag:\n",
    "            break\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        # debug\n",
    "        #print(\"batch.shape:{}\".format(batch.shape))\n",
    "        # if batch is not None:\n",
    "\n",
    "        # face_detection\n",
    "        cropped_face = class_face_detection.predict(batch)\n",
    "\n",
    "        # head_pose_estimation\n",
    "        head_pose_angles = class_head_pose_estimation.predict(cropped_face)\n",
    "\n",
    "        # debug\n",
    "        #print(\"angle_y_fc:{}, angle_p_fc:{}, angle_r_fc:{}\".format(head_pose_angles[0], head_pose_angles[1], head_pose_angles[2]))\n",
    "\n",
    "        # facial_landmarks_detection\n",
    "        left_eye_image, right_eye_image, left_eye_center, right_eye_center= class_facial_landmarks_detection.predict(cropped_face)\n",
    "\n",
    "        # gaze_estimation\n",
    "        x, y, gaze_vector = class_gaze_estimation.predict(left_eye_image, right_eye_image, head_pose_angles)\n",
    "\n",
    "        cv2.line(cropped_face, left_eye_center, (int(left_eye_center[0] + gaze_vector[0] * 100), int(left_eye_center[1] - gaze_vector[1] * 100)), (255,255,255), 2)\n",
    "        cv2.line(cropped_face, right_eye_center, (int(right_eye_center[0] + gaze_vector[0] * 100), int(right_eye_center[1] - gaze_vector[1] * 100)), (255,255,255), 2)\n",
    "\n",
    "        # output\n",
    "        #cv2.imshow('output', batch)\n",
    "        #cv2.waitKey(30)\n",
    "        #cv2.imwrite('output.jpg', batch);\n",
    "\n",
    "        out_video.write(batch)\n",
    "\n",
    "        # MouseController\n",
    "        #mc.move(x, y)\n",
    "\n",
    "    total_time = time.time() - start_inference_time\n",
    "    total_inference_time = round(total_time, 1)\n",
    "    fps = counter/total_inference_time\n",
    "\n",
    "    #print(\"total_model_load_time:{}, total_inference_time:{}, fps:{}\".format(total_model_load_time, total_inference_time, fps))\n",
    "    print(total_inference_time)\n",
    "    print(fps)\n",
    "    print(total_model_load_time)\n",
    "\n",
    "    feed.close()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=ArgumentParser()\n",
    "    parser.add_argument(\"-mfd\", \"--model_face_detection\", required=True)\n",
    "    parser.add_argument(\"-mhpe\", \"--model_head_pose_estimation\", required=True)\n",
    "    parser.add_argument(\"-mfld\", \"--model_facial_landmarks_detection\", required=True)\n",
    "    parser.add_argument(\"-mge\", \"--model_gaze_estimation\", required=True)\n",
    "\n",
    "    parser.add_argument(\"-d\", \"--device\", default=\"CPU\")\n",
    "    parser.add_argument(\"-t\", \"--threshold\", default=0.9)\n",
    "    parser.add_argument(\"-i\", \"--input_path\", required=True)\n",
    "\n",
    "    args=parser.parse_args() \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. input_feeder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_feeder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_feeder.py\n",
    "\n",
    "'''\n",
    "This class can be used to feed input from an image, webcam, or video to your model.\n",
    "Sample usage:\n",
    "    feed=InputFeeder(input_type='video', input_file='video.mp4')\n",
    "    feed.load_data()\n",
    "    for batch in feed.next_batch():\n",
    "        do_something(batch)\n",
    "    feed.close()\n",
    "'''\n",
    "import cv2\n",
    "from numpy import ndarray\n",
    "\n",
    "class InputFeeder:\n",
    "    def __init__(self, input_type, input_file=None):\n",
    "        '''\n",
    "        input_type: str, The type of input. Can be 'video' for video file, 'image' for image file,\n",
    "                    or 'cam' to use webcam feed.\n",
    "        input_file: str, The file that contains the input image or video file. Leave empty for cam input_type.\n",
    "        '''\n",
    "        self.input_type=input_type\n",
    "        if input_type=='video' or input_type=='image':\n",
    "            self.input_file=input_file\n",
    "\n",
    "    def load_data(self):\n",
    "        if self.input_type=='video':\n",
    "            self.cap=cv2.VideoCapture(self.input_file)\n",
    "        elif self.input_type=='cam':\n",
    "            self.cap=cv2.VideoCapture(0)\n",
    "        else:\n",
    "            self.cap=cv2.imread(self.input_file)\n",
    "\n",
    "        # debug\n",
    "        #print(\"self.input_file:{}\".format(self.input_file))\n",
    "\n",
    "    def next_batch(self):\n",
    "        '''\n",
    "        Returns the next image from either a video file or webcam.\n",
    "        If input_type is 'image', then it returns the same image.\n",
    "        '''\n",
    "        while True:\n",
    "            for _ in range(10):\n",
    "                flag, frame=self.cap.read()\n",
    "            yield flag, frame\n",
    "\n",
    "    def get_info(self):\n",
    "        initial_w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        initial_h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        initial_fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n",
    "        return initial_w, initial_h, initial_fps\n",
    "\n",
    "    def close(self):\n",
    "        '''\n",
    "        Closes the VideoCapture.\n",
    "        '''\n",
    "        if not self.input_type=='image':\n",
    "            self.cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. face_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting face_detection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile face_detection.py\n",
    "\n",
    "'''\n",
    "This is a sample class for a model. You may choose to use it as-is or make any changes to it.\n",
    "This has been provided just to give you an idea of how to structure your model class.\n",
    "'''\n",
    "import cv2\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "class ModelFaceDetection:\n",
    "    '''\n",
    "    Class for the Face Detection Model.\n",
    "    '''\n",
    "    def __init__(self, model_name, device='CPU', threshold=0.9):\n",
    "        '''\n",
    "        TODO: Use this to set your instance variables.\n",
    "        '''\n",
    "        self.model_weights = model_name+'.bin'\n",
    "        self.model_structure = model_name+'.xml'\n",
    "        self.device = device\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.core = IECore()\n",
    "        self.model = self.core.read_network(model=self.model_structure, weights=self.model_weights)\n",
    "\n",
    "        self.input_name = next(iter(self.model.input_info))\n",
    "        self.input_shape = self.model.inputs[self.input_name].shape\n",
    "        self.output_name = next(iter(self.model.outputs))\n",
    "        self.output_shape = self.model.outputs[self.output_name].shape\n",
    "\n",
    "    def load_model(self):\n",
    "        '''\n",
    "        TODO: You will need to complete this method.\n",
    "        This method is for loading the model to the device specified by the user.\n",
    "        If your model requires any Plugins, this is where you can load them.\n",
    "        '''\n",
    "        self.net = self.core.load_network(network=self.model, device_name=self.device, num_requests=1)\n",
    "\n",
    "    def predict(self, image):\n",
    "        '''\n",
    "        TODO: You will need to complete this method.\n",
    "        This method is meant for running predictions on the input image.\n",
    "        '''\n",
    "        frame = self.preprocess_input(image)\n",
    "        outputs = self.net.infer({self.input_name:frame})\n",
    "        cropped_face = self.preprocess_output(image, outputs[self.output_name])\n",
    "\n",
    "        return cropped_face\n",
    "\n",
    "    def check_model(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess_input(self, image):\n",
    "        '''\n",
    "        Before feeding the data into the model for inference,\n",
    "        you might have to preprocess it. This function is where you can do that.\n",
    "        '''\n",
    "        # debug\n",
    "        #print(\"image.shape:{}\".format(image.shape))\n",
    "        #print(\"self.input_shape:{}\".format(self.input_shape))\n",
    "\n",
    "        # input shape: BxCxHxW    \n",
    "        height = self.input_shape[2]\n",
    "        width = self.input_shape[3]\n",
    "\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        image = image.transpose((2,0,1))\n",
    "        image = image.reshape(1, 3, height, width)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def preprocess_output(self, image, outputs):\n",
    "        '''\n",
    "        Before feeding the output of this model to the next model,\n",
    "        you might have to preprocess the output. This function is where you can do that.\n",
    "        '''\n",
    "        #coords = []\n",
    "\n",
    "        # output shape: [1, 1, N, 7]\n",
    "        for box in outputs[0][0]:\n",
    "\n",
    "            # only keep probability greater than the threshold\n",
    "            #if box[2] >= self.threshold:\n",
    "            if box[2] >= 0.9:\n",
    "                xmin = int(box[3] * self.width)\n",
    "                ymin = int(box[4] * self.height)\n",
    "                xmax = int(box[5] * self.width)\n",
    "                ymax = int(box[6] * self.height)\n",
    "\n",
    "                #coords.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "                cropped_face = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 1)\n",
    "\n",
    "        #return coords\n",
    "        return cropped_face\n",
    "\n",
    "    def initial_size(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. head_pose_estimation.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting head_pose_estimation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile head_pose_estimation.py\n",
    "\n",
    "'''\n",
    "This is a sample class for a model. You may choose to use it as-is or make any changes to it.\n",
    "This has been provided just to give you an idea of how to structure your model class.\n",
    "'''\n",
    "import cv2\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "class ModelHeadPoseEstimation:\n",
    "    '''\n",
    "    Class for the Face Detection Model.\n",
    "    '''\n",
    "    def __init__(self, model_name, device='CPU'):\n",
    "        '''\n",
    "        TODO: Use this to set your instance variables.\n",
    "        '''\n",
    "        self.model_weights=model_name+'.bin'\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        self.device=device\n",
    "\n",
    "        self.core = IECore()\n",
    "        self.model = self.core.read_network(model=self.model_structure, weights=self.model_weights)\n",
    "\n",
    "        self.input_name = next(iter(self.model.inputs))\n",
    "        self.input_shape = self.model.inputs[self.input_name].shape\n",
    "        self.output_name = next(iter(self.model.outputs))\n",
    "        self.output_shape = self.model.outputs[self.output_name].shape\n",
    "\n",
    "    def load_model(self):\n",
    "        '''\n",
    "        TODO: You will need to complete this method.\n",
    "        This method is for loading the model to the device specified by the user.\n",
    "        If your model requires any Plugins, this is where you can load them.\n",
    "        '''\n",
    "        self.net = self.core.load_network(network=self.model, device_name=self.device, num_requests=1)\n",
    "\n",
    "    def predict(self, image):\n",
    "        '''\n",
    "        TODO: You will need to complete this method.\n",
    "        This method is meant for running predictions on the input image.\n",
    "        '''\n",
    "        frame = self.preprocess_input(image)\n",
    "        outputs = self.net.infer({self.input_name:frame})\n",
    "\n",
    "        # debug\n",
    "        #print(\"outputs:{}\".format(outputs))\n",
    "\n",
    "        #coords = self.preprocess_output(outputs[self.output_name])\n",
    "        return self.preprocess_output(outputs)\n",
    "\n",
    "    def check_model(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess_input(self, image):\n",
    "        '''\n",
    "        Before feeding the data into the model for inference,\n",
    "        you might have to preprocess it. This function is where you can do that.\n",
    "        '''\n",
    "        # input shape: 1xCxHxW    \n",
    "        height = self.input_shape[2]\n",
    "        width = self.input_shape[3]\n",
    "\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        image = image.transpose((2,0,1))\n",
    "        image = image.reshape(1, 3, height, width)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def preprocess_output(self, outputs):\n",
    "        '''\n",
    "        Before feeding the output of this model to the next model,\n",
    "        you might have to preprocess the output. This function is where you can do that.\n",
    "        '''\n",
    "        # angle_y_fc: [1, 1] - Estimated yaw\n",
    "        # angle_p_fc: [1, 1] - Estimated pitch\n",
    "        # angle_r_fc: [1, 1] - Estimated roll\n",
    "        \n",
    "        head_pose_angles = []\n",
    "        head_pose_angles.append(outputs['angle_y_fc'][0][0])\n",
    "        head_pose_angles.append(outputs['angle_p_fc'][0][0])\n",
    "        head_pose_angles.append(outputs['angle_r_fc'][0][0])\n",
    "\n",
    "        return head_pose_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. facial_landmarks_detection.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting facial_landmarks_detection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile facial_landmarks_detection.py\n",
    "\n",
    "'''\n",
    "This is a sample class for a model. You may choose to use it as-is or make any changes to it.\n",
    "This has been provided just to give you an idea of how to structure your model class.\n",
    "'''\n",
    "import cv2\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "class ModelFacialLandmarksDetection:\n",
    "    '''\n",
    "    Class for the Face Detection Model.\n",
    "    '''\n",
    "    def __init__(self, model_name, device='CPU'):\n",
    "        '''\n",
    "        TODO: Use this to set your instance variables.\n",
    "        '''\n",
    "        self.model_weights=model_name+'.bin'\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        self.device=device\n",
    "\n",
    "        self.core = IECore()\n",
    "        self.model = self.core.read_network(model=self.model_structure, weights=self.model_weights)\n",
    "\n",
    "        self.input_name = next(iter(self.model.inputs))\n",
    "        self.input_shape = self.model.inputs[self.input_name].shape\n",
    "        self.output_name = next(iter(self.model.outputs))\n",
    "        self.output_shape = self.model.outputs[self.output_name].shape\n",
    "\n",
    "    def load_model(self):\n",
    "        '''\n",
    "        TODO: You will need to complete this method.\n",
    "        This method is for loading the model to the device specified by the user.\n",
    "        If your model requires any Plugins, this is where you can load them.\n",
    "        '''\n",
    "        self.net = self.core.load_network(network=self.model, device_name=self.device, num_requests=1)\n",
    "\n",
    "    def predict(self, image):\n",
    "        '''\n",
    "        TODO: You will need to complete this method.\n",
    "        This method is meant for running predictions on the input image.\n",
    "        '''\n",
    "        frame = self.preprocess_input(image)\n",
    "        outputs = self.net.infer({self.input_name:frame})\n",
    "\n",
    "        # debug\n",
    "        #print(\"outputs:{}\".format(outputs))\n",
    "\n",
    "        return self.preprocess_output(image, outputs[self.output_name][0])\n",
    "\n",
    "    def check_model(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess_input(self, image):\n",
    "        '''\n",
    "        Before feeding the data into the model for inference,\n",
    "        you might have to preprocess it. This function is where you can do that.\n",
    "        '''\n",
    "        # input shape: BxCxHxW    \n",
    "        height = self.input_shape[2]\n",
    "        width = self.input_shape[3]\n",
    "\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        image = image.transpose((2,0,1))\n",
    "        image = image.reshape(1, 3, height, width)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def preprocess_output(self, image, outputs):\n",
    "        '''\n",
    "        Before feeding the output of this model to the next model,\n",
    "        you might have to preprocess the output. This function is where you can do that.\n",
    "        '''\n",
    "        # output shape: [1, 10], containing a row-vector of 10 floating point values for five landmarks coordinates\n",
    "\n",
    "        # debug\n",
    "        #print(\"image.shape:{}\".format(image.shape))\n",
    "        #print(\"x0:{}, y0:{}\".format(outputs[0][0][0], outputs[1][0][0]))\n",
    "        #print(\"x1:{}, y1:{}\".format(outputs[2][0][0], outputs[3][0][0]))\n",
    "\n",
    "        height, width, channel = image.shape\n",
    "\n",
    "        # left eye\n",
    "        left_eye_xmin = int(outputs[0][0][0] * width - 20)\n",
    "        left_eye_xmax = int(outputs[0][0][0] * width + 20)\n",
    "        left_eye_ymin = int(outputs[1][0][0] * height - 20)\n",
    "        left_eye_ymax = int(outputs[1][0][0] * height + 20)\n",
    "\n",
    "        left_eye_image = image[left_eye_ymin:left_eye_ymax, left_eye_xmin:left_eye_xmax]\n",
    "        left_eye_center = int((left_eye_xmin + left_eye_xmax) / 2), int((left_eye_ymin + left_eye_ymax) / 2)\n",
    "        cv2.rectangle(image, (left_eye_xmin, left_eye_ymin), (left_eye_xmax, left_eye_ymax), (0, 0, 255), 1)\n",
    "\n",
    "        # right eye\n",
    "        right_eye_xmin = int(outputs[2][0][0] * width - 20)\n",
    "        right_eye_xmax = int(outputs[2][0][0] * width + 20)\n",
    "        right_eye_ymin = int(outputs[3][0][0] * height - 20)\n",
    "        right_eye_ymax = int(outputs[3][0][0] * height + 20)\n",
    "\n",
    "        right_eye_image = image[right_eye_ymin:right_eye_ymax, right_eye_xmin:right_eye_xmax]\n",
    "        right_eye_center = int((right_eye_xmin + right_eye_xmax) / 2), int((right_eye_ymin + right_eye_ymax) / 2)\n",
    "        cv2.rectangle(image, (right_eye_xmin, right_eye_ymin), (right_eye_xmax, right_eye_ymax), (0, 0, 255), 1)\n",
    "\n",
    "        # debug\n",
    "        #print(\"left_eye_center:{}, right_eye_center:{}\".format(left_eye_center, right_eye_center))\n",
    "\n",
    "        return left_eye_image, right_eye_image, left_eye_center, right_eye_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6. gaze_estimation.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gaze_estimation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gaze_estimation.py\n",
    "\n",
    "'''\n",
    "This is a sample class for a model. You may choose to use it as-is or make any changes to it.\n",
    "This has been provided just to give you an idea of how to structure your model class.\n",
    "'''\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "class ModelGazeEstimation:\n",
    "    '''\n",
    "    Class for the Face Detection Model.\n",
    "    '''\n",
    "    def __init__(self, model_name, device='CPU'):\n",
    "        '''\n",
    "        TODO: Use this to set your instance variables.\n",
    "        '''\n",
    "        self.model_weights=model_name+'.bin'\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        self.device=device\n",
    "\n",
    "        self.core = IECore()\n",
    "        self.model = self.core.read_network(model=self.model_structure, weights=self.model_weights)\n",
    "\n",
    "        self.input_name = [i for i in self.model.inputs.keys()]\n",
    "\n",
    "        # debug\n",
    "        #print(\"self.input_name:{}\".format(self.input_name))\n",
    "        #print(\"self.model.inputs[self.input_name[1]].shape:{}\".format(self.model.inputs[self.input_name[1]].shape))\n",
    "\n",
    "        self.input_shape=self.model.inputs[self.input_name[1]].shape\n",
    "        self.output_name=next(iter(self.model.outputs))\n",
    "        self.output_shape=self.model.outputs[self.output_name].shape\n",
    "        \n",
    "    def load_model(self):\n",
    "        '''\n",
    "        TODO: You will need to complete this method.\n",
    "        This method is for loading the model to the device specified by the user.\n",
    "        If your model requires any Plugins, this is where you can load them.\n",
    "        '''\n",
    "        self.net = self.core.load_network(network=self.model, device_name=self.device, num_requests=1)\n",
    "\n",
    "    def predict(self, left_eye_image, right_eye_image, head_pose_angles):\n",
    "        '''\n",
    "        TODO: You will need to complete this method.\n",
    "        This method is meant for running predictions on the input image.\n",
    "        '''\n",
    "        left_eye_frame = self.preprocess_input(left_eye_image)\n",
    "        right_eye_frame = self.preprocess_input(right_eye_image)\n",
    "\n",
    "        net_input = {'left_eye_image': left_eye_frame, 'right_eye_image': right_eye_frame, 'head_pose_angles': head_pose_angles}\n",
    "        outputs = self.net.infer(inputs=net_input)\n",
    "\n",
    "        # debug\n",
    "        #print(\"outputs:{}\".format(outputs))\n",
    "\n",
    "        return self.preprocess_output(outputs, head_pose_angles)\n",
    "\n",
    "    def check_model(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess_input(self, image):\n",
    "        '''\n",
    "        Before feeding the data into the model for inference,\n",
    "        you might have to preprocess it. This function is where you can do that.\n",
    "        '''\n",
    "        # head_pose_angles: BxC\n",
    "        # left_eye_image: BxCxHxW\n",
    "        # right_eye_image: BxCxHxW\n",
    "\n",
    "        height = self.input_shape[2]\n",
    "        width = self.input_shape[3]\n",
    "\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        image = image.transpose((2,0,1))\n",
    "        image = image.reshape(1, 3, height, width)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def preprocess_output(self, outputs, head_pose_angles):\n",
    "        '''\n",
    "        Before feeding the output of this model to the next model,\n",
    "        you might have to preprocess the output. This function is where you can do that.\n",
    "        '''\n",
    "        gaze_vector = outputs[self.output_name][0]\n",
    "\n",
    "        angle_r_fc = head_pose_angles[2]\n",
    "        r_cos = math.cos(angle_r_fc * math.pi / 180.0)\n",
    "        r_sin = math.sin(angle_r_fc * math.pi / 180.0)\n",
    "\n",
    "        x = gaze_vector[0] * r_cos + gaze_vector[1] * r_sin\n",
    "        y = -gaze_vector[0] * r_sin+ gaze_vector[1] * r_cos\n",
    "\n",
    "        #debug\n",
    "        #print(\"gaze_vector:{}\".format(gaze_vector))\n",
    "        #print(\"x:{}, y:{}\".format(x, y))\n",
    "\n",
    "        return x, y, gaze_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. mouse_controller.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mouse_controller.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mouse_controller.py\n",
    "\n",
    "'''\n",
    "This is a sample class that you can use to control the mouse pointer.\n",
    "It uses the pyautogui library. You can set the precision for mouse movement\n",
    "(how much the mouse moves) and the speed (how fast it moves) by changing \n",
    "precision_dict and speed_dict.\n",
    "Calling the move function with the x and y output of the gaze estimation model\n",
    "will move the pointer.\n",
    "This class is provided to help get you started; you can choose whether you want to use it or create your own from scratch.\n",
    "'''\n",
    "import pyautogui\n",
    "\n",
    "class MouseController:\n",
    "    def __init__(self, precision, speed):\n",
    "        precision_dict={'high':100, 'low':1000, 'medium':500}\n",
    "        speed_dict={'fast':1, 'slow':10, 'medium':5}\n",
    "\n",
    "        self.precision=precision_dict[precision]\n",
    "        self.speed=speed_dict[speed]\n",
    "\n",
    "        pyautogui.FAILSAFE = 0\n",
    "\n",
    "    def move(self, x, y):\n",
    "        pyautogui.moveRel(x*self.precision, -1*y*self.precision, duration=self.speed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
